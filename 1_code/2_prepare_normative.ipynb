{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import os, sys, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy.io as sio\n",
    "\n",
    "# Stats\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import pingouin as pg\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.matlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/lindenmp/Google-Drive-Penn/work/research_projects/normative_neurodev_cs_t1/1_code/')\n",
    "from func import set_proj_env, get_synth_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_str = 'train_test'\n",
    "exclude_str = 't1Exclude' # 't1Exclude' 'fsFinalExclude'\n",
    "parc_str = 'schaefer' # 'schaefer' 'lausanne'\n",
    "parc_scale = 400 # 200 400 | 60 125 250\n",
    "parcel_names, parcel_loc, drop_parcels, num_parcels, yeo_idx, yeo_labels = set_proj_env(exclude_str = exclude_str, parc_str = parc_str, parc_scale = parc_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t1Exclude_schaefer_400_'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output file prefix\n",
    "outfile_prefix = exclude_str+'_'+parc_str+'_'+str(parc_scale)+'_'\n",
    "outfile_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup directory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lindenmp/Google-Drive-Penn/work/research_projects/normative_neurodev_cs_t1/2_pipeline/2_prepare_normative/out\n"
     ]
    }
   ],
   "source": [
    "outputdir = os.path.join(os.environ['PIPELINEDIR'], '2_prepare_normative', 'out')\n",
    "print(outputdir)\n",
    "if not os.path.exists(outputdir): os.makedirs(outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lindenmp/Google-Drive-Penn/work/research_projects/normative_neurodev_cs_t1/3_output/figs\n"
     ]
    }
   ],
   "source": [
    "figdir = os.path.join(os.environ['OUTPUTDIR'], 'figs')\n",
    "print(figdir)\n",
    "if not os.path.exists(figdir): os.makedirs(figdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1376, 49)\n",
      "(1376, 801)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(os.path.join(os.environ['PIPELINEDIR'], '1_compute_node_features', 'out', outfile_prefix+'df.csv'))\n",
    "df.set_index(['bblid', 'scanid'], inplace = True)\n",
    "\n",
    "df_node = pd.read_csv(os.path.join(os.environ['PIPELINEDIR'], '1_compute_node_features', 'out', outfile_prefix+'df_node.csv'))\n",
    "df_node.set_index(['bblid', 'scanid'], inplace = True)\n",
    "\n",
    "# adjust sex to 0 and 1\n",
    "# now: male = 0, female = 1\n",
    "df['sex_adj'] = df.sex - 1\n",
    "print(df.shape)\n",
    "print(df_node.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 308 Test: 1068\n"
     ]
    }
   ],
   "source": [
    "print('Train:', np.sum(df[train_test_str] == 0), 'Test:', np.sum(df[train_test_str] == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct|vol\n"
     ]
    }
   ],
   "source": [
    "metrics = ['ct', 'vol']\n",
    "my_str = '|'.join(metrics); print(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.any(df_node.filter(regex = my_str, axis = 1) < 0):\n",
    "    print('WARNING: some regional values are <0, box cox will fail')\n",
    "\n",
    "if np.any(df_node.filter(regex = my_str, axis = 1) == 0):\n",
    "    print('WARNING: some regional values are == 0, box cox will fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping...\n"
     ]
    }
   ],
   "source": [
    "rank_r = np.zeros(df_node.filter(regex = my_str).shape[1])\n",
    "\n",
    "# normalise\n",
    "if norm_data:\n",
    "    for i, col in enumerate(df_node.filter(regex = my_str).columns):\n",
    "        # normalize regional metric\n",
    "        x = sp.stats.boxcox(df_node.loc[:,col])[0]\n",
    "        # check if rank order is preserved\n",
    "        rank_r[i] = sp.stats.spearmanr(df_node.loc[:,col],x)[0]\n",
    "        # store normalized version\n",
    "        df_node.loc[:,col] = x\n",
    "    print(np.sum(rank_r < .99))\n",
    "else:\n",
    "    print('Skipping...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare files for normative modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ageAtScan1_Years', 'sex_adj']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Note, 'ageAtScan1_Years' is assumed to be covs[0] and 'sex_adj' is assumed to be covs[1]\n",
    "# if more than 2 covs are to be used, append to the end and age/sex will be duplicated accordingly in the forward model\n",
    "covs = ['ageAtScan1_Years', 'sex_adj']\n",
    "\n",
    "print(covs)\n",
    "num_covs = len(covs)\n",
    "print(num_covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_str_2 = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary model (train/test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out training\n",
    "df[df[train_test_str] == 0].to_csv(os.path.join(outputdir, outfile_prefix+'train.csv'))\n",
    "df[df[train_test_str] == 0].to_csv(os.path.join(outputdir, outfile_prefix+'cov_train.txt'), columns = covs, sep = ' ', index = False, header = False)\n",
    "\n",
    "# Write out test\n",
    "df[df[train_test_str] == 1].to_csv(os.path.join(outputdir, outfile_prefix+'test.csv'))\n",
    "df[df[train_test_str] == 1].to_csv(os.path.join(outputdir, outfile_prefix+'cov_test.txt'), columns = covs, sep = ' ', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 features written out for normative modeling\n"
     ]
    }
   ],
   "source": [
    "# Write out training\n",
    "resp_train = df_node[df_node[train_test_str] == 0].drop(train_test_str, axis = 1)\n",
    "mask = np.all(np.isnan(resp_train), axis = 1)\n",
    "if np.any(mask): print(\"Warning: NaNs in response train\")\n",
    "resp_train.to_csv(os.path.join(outputdir, outfile_prefix+'resp_train.csv'))\n",
    "resp_train.to_csv(os.path.join(outputdir, outfile_prefix+'resp_train.txt'), sep = ' ', index = False, header = False)\n",
    "\n",
    "# Write out test\n",
    "resp_test = df_node[df_node[train_test_str] == 1].drop(train_test_str, axis = 1)\n",
    "mask = np.all(np.isnan(resp_test), axis = 1)\n",
    "if np.any(mask): print(\"Warning: NaNs in response train\")\n",
    "resp_test.to_csv(os.path.join(outputdir, outfile_prefix+'resp_test.csv'))\n",
    "resp_test.to_csv(os.path.join(outputdir, outfile_prefix+'resp_test.txt'), sep = ' ', index = False, header = False)\n",
    "\n",
    "print(str(resp_train.shape[1]) + ' features written out for normative modeling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 2)\n"
     ]
    }
   ],
   "source": [
    "# Synthetic cov data\n",
    "x = get_synth_cov(df, cov = 'ageAtScan1_Years', stp = 1)\n",
    "\n",
    "if 'sex_adj' in covs:\n",
    "    # Produce gender dummy variable for one repeat --> i.e., to account for two runs of ages, one per gender\n",
    "    gender_synth = np.concatenate((np.ones(x.shape),np.zeros(x.shape)), axis = 0)\n",
    "\n",
    "# concat\n",
    "synth_cov = np.concatenate((np.matlib.repmat(x, 2, 1), np.matlib.repmat(gender_synth, 1, 1)), axis = 1)\n",
    "print(synth_cov.shape)\n",
    "\n",
    "# write out\n",
    "np.savetxt(os.path.join(outputdir, outfile_prefix+'cov_test_forward.txt'), synth_cov, delimiter = ' ', fmt = ['%.1f', '%.d'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
